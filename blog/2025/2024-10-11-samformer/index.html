<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="goal-"> <a id="goal"></a>Goal üöÄ</h2> <blockquote> <p>When a rigorous scientific method leads to an efficient implementation.</p> </blockquote> <p>In this blog post, we focus on <strong>SAMformer</strong>*, a transformer-based architecture for time series forecasting proposed in <a href="https://arxiv.org/pdf/2402.10198" rel="external nofollow noopener" target="_blank"><em>SAMformer: Unlocking the Potential of Transformers in Time Series Forecasting</em></a> <d-cite key="pmlr-v235-ilbert24a"></d-cite>. SAMformer combines Sharpness-Aware Minimization (SAM) <d-cite key="foret2021sharpnessaware"></d-cite> and channel-wise attention to obtain a light-weight SOTA model with improved robustness and signal propagation compared to its competitors. This blog aims to provide a high-level view of the motivation behind SAMformer while explaining how to implement it. For the reader interested in more mathematical details or to play with SAMformer, the paper is on <a href="https://arxiv.org/pdf/2402.10198" rel="external nofollow noopener" target="_blank">arXiv</a>, and the code can be found on <a href="https://github.com/romilbert/samformer" rel="external nofollow noopener" target="_blank">github</a>.</p> <p>1) Problem: transformers nuls en TS forecasting + very complicated and large-scale models ‚Äì&gt; hard to identify the failure. 2) We simplify transformer to only keep the key components 3) Problem identification: trainability issues 4) Possible solution: sigma reparam or SAM 5) SAM works ‚Äì&gt; putting evertyhing together</p> <h2 id="motivation-">Motivation üîé</h2> <p>‚ÄúOn va droit au but, allez voir le papier pour plus de detail.‚Äù (TO DO, something like ‚ÄúWe‚Äôll keep it concise, refer to the paper for more details.‚Äù). Proposition : Traditional transformer models for time series forecasting are often complex and large, making it difficult to pinpoint and address their weaknesses. SAMformer addresses this by streamlining the architecture to include only essential components, enhancing simplicity without compromising performance. Trainability issues are identified during this simplification and are tackled using Sharpness-Aware Minimization (SAM), which proved highly effective. By integrating SAM with channel-wise attention, SAMformer achieves state-of-the-art performance with a lightweight and robust design, making it a superior choice for time series forecasting.</p> <p>Time series forecasting has many applications in real-world scenarios, e.g., to anticipate cardiac arrhythmia in ECG signals, predict electricity consumption to match future demand, or forecast stock market prices (an exciting topic in times of inflation). This is notoriously challenging, especially in multivariate and long-term settings, due to feature correlations and long-term temporal dependencies in time series. Moreover, Zeng et al. recently showed that, despite their success in NLP and Computer Vision, transformers were not effective on this task <d-cite key="zeng2022transformerseffectivetimeseries"></d-cite>. More specifically, they showed that the claimed SOTA transformers could be beaten by simpler and smaller methods such as linear models.</p> <p>Since traditional transformer models for time series forecasting are often complex and large, making it difficult to pinpoint and address their weaknesses.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_samformer/meme_dogs.png" sizes="95vw"></source> <img src="/assets/img/blog_samformer/meme_dogs.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="samformer-Ô∏è">SAMformer ‚öîÔ∏è</h2> <h3 id="trainability-issues-of-the-attention">Trainability Issues of the Attention</h3> <p>To identify the problem, we simplify the original Transformer <d-cite key="vaswani2017"></d-cite> to only keep the key components.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_samformer/sharpness_entropy_collapse_sam.png" sizes="95vw"></source> <img src="/assets/img/blog_samformer/sharpness_entropy_collapse_sam.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="sam-to-the-rescue">SAM to the rescue</h3> <p>There are two possible solutions:</p> <ul> <li>$\sigma$-reparam <d-cite key="zhai2023sigmareparam"></d-cite>:</li> <li>SAM <d-cite key="foret2021sharpnessaware"></d-cite>:</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_samformer/toy_exp_losses_val_all_methods.png" sizes="95vw"></source> <img src="/assets/img/blog_samformer/toy_exp_losses_val_all_methods.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="putting-everything-together">Putting Everything Together</h3> <p>Now it works on our toy example: congrats you can now solve linear regression tasks. Hum, what about true time series data? We are only one step away from the optimal architecture: add revin <d-cite key="kim2022reversible"></d-cite></p> <p>In the end, SAMformer consists of 5 layers: RevIN normalization, channel-wise attention, residual connection, linear forecasting, and RevIN denormalization. And we are SOTA:</p> <p>fig: add table and/or result figure (e.g. generalization plots with stars).</p> <h2 id="getting-your-hands-dirty-Ô∏è">Getting your hands dirty üñ•Ô∏è</h2> <p>In this section, we discuss the implementation of SAMformer.</p> <h3 id="overview">Overview</h3> <p>The original implementation of the SAMformer architecture makes use of modern deep learning frameworks such as <code class="language-plaintext highlighter-rouge">PyTorch</code> or <code class="language-plaintext highlighter-rouge">TensorFlow</code> and can be found <a href="https://github.com/romilbert/samformer" rel="external nofollow noopener" target="_blank">here</a>.</p> <h3 id="main-components">Main Components</h3> <p>As can be seen below, SAMformer consists of 5 layers:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_samformer/samformer_arch.png" sizes="95vw"></source> <img src="/assets/img/blog_samformer/samformer_arch.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>It leads to a shallow transformer with a single head and a single encoder that can be trained with SAM <d-cite key="foret2021sharpnessaware"></d-cite>.</p> <p>We provide a snippet of SAMformer (few) code lines below for the interested reader.</p> <details><summary>SAMformer Implementation</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">SAMFormerArchitecture</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">hid_dim</span><span class="p">,</span> <span class="n">pred_horizon</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">revin</span> <span class="o">=</span> <span class="nc">RevIN</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">num_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">compute_keys</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">hid_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">compute_queries</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">hid_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">compute_values</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear_forecaster</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">pred_horizon</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

        <span class="c1"># RevIN Normalization
</span>        <span class="n">x_norm</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">revin</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">norm</span><span class="sh">'</span><span class="p">)</span> 
        <span class="n">x_norm</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (n, D, L)
</span>
        <span class="c1"># Channel-Wise Attention
</span>        <span class="n">queries</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_queries</span><span class="p">(</span><span class="n">x_norm</span><span class="p">)</span> <span class="c1"># (n, D, hid_dim)
</span>        <span class="n">keys</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_keys</span><span class="p">(</span><span class="n">x_norm</span><span class="p">)</span> <span class="c1"># (n, D, hid_dim)
</span>        <span class="n">values</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_values</span><span class="p">(</span><span class="n">x_norm</span><span class="p">)</span> <span class="c1"># (n, D, L)
</span>        <span class="n">att_score</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span> <span class="c1"># (n, D, L)
</span>
        <span class="c1"># Residual Connection
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">x_norm</span> <span class="o">+</span> <span class="n">att_score</span> <span class="c1"># (n, D, L)
</span>
        <span class="c1"># Linear Forecasting
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear_forecaster</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="c1"># (n, D, H)
</span>
        <span class="c1"># RevIN Denormalization
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">revin</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">denorm</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (n, D, H)
</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div> </details> <h2 id="future-work">Future Work</h2> <p>Sigma reparam bla bla (citer Sinkformer <d-cite key="pmlr-v151-sander22a"></d-cite> + rank and signal propagation work on attention (attention is not all u need + signal propagation in transformer).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_samformer/nuclear_norm.png" sizes="95vw"></source> <img src="/assets/img/blog_samformer/nuclear_norm.png" class="img-fluid rounded z-depth-0" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="conclusion">Conclusion</h2> <h2 id="acknowledgments-"> <a id="acknowledgments"></a>Acknowledgments üôèüèæ</h2> <p>We thank TBD for taking the time to proofread this blog post. SAMformer <d-cite key="pmlr-v235-ilbert24a"></d-cite> is the first published paper of Ambroise‚Äôs thesis on transformers and distribution shifts. He thanks all his co-authors and particularly his supervisor, Ievgen Redko, for the advice, trust, and freedom he provided during this project.</p> <p>For any further questions, please feel free to leave a comment or contact us by mail!</p> </body></html>